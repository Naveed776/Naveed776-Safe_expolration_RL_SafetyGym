### Conclusion

The system operates with an average episode length of 1000 steps and achieves an average reward of 10.7. Running at 237 frames per second, it completes 34 iterations over 430 seconds, accumulating 102,000 timesteps.

Key training metrics show stable performance:
- **Approximate KL Divergence:** 0.0079
- **Clip Fraction:** 0.0731 with a clip range of 0.2
- **Entropy Loss:** -2.75
- **Explained Variance:** 0.0222
- **Learning Rate:** 0.0001
- **Loss:** -0.00895
- **Policy Gradient Loss:** -0.00963
- **Standard Deviation:** 0.959
- **Value Loss:** 0.0223

Episode returns vary between 9.495 and 14.940, indicating variability in performance across episodes.

In summary, while the system demonstrates stable training metrics, there is room for improvement in achieving more consistent and higher average rewards across episodes. Further optimization could focus on refining policy adjustments and enhancing learning efficiency.


[CarButton1.webm](https://github.com/Naveed776/Safe_expolration_RL_SafetyGym/assets/91262613/a7d8abcf-8e18-4bd4-b168-55e750db8806)



![CarButton1](https://github.com/Naveed776/Safe_expolration_RL_SafetyGym/assets/91262613/be01ae28-8a3b-4b15-aa95-9e1a5552ab42)
