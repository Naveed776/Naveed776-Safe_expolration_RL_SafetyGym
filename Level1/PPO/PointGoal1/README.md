### Conclusion

The system demonstrates efficient performance and effective learning. With an average episode length of 1000 steps and an average reward of 35.4, the simulation operates at a high frame rate of 347 frames per second, completing 334 iterations over 2879 seconds, covering a total of 1,002,000 timesteps.

Training metrics indicate stable policy updates, moderate exploration, and good learning:
- Approximate KL divergence: 0.0091
- Clip fraction: 0.123 within a clip range of 0.2
- Entropy loss: -2.81
- Explained variance: 0.493
- Learning rate: 0.0001
- Loss: 0.0546
- Policy gradient loss: -0.00622
- Standard deviation: 0.993
- Value loss: 0.101

Episode returns are generally positive, ranging from 33.327 to 39.828, with costs varying across episodes but showing an overall trend towards efficiency.

In summary, the system shows robust performance and stability in training, with consistent rewards and effective learning. Future improvements could focus on further reducing episode costs to optimize performance.


[PointGoal1.webm](https://github.com/Naveed776/Safe_expolration_RL_SafetyGym/assets/91262613/81c8a37f-7fcc-451c-b4ab-c0535f64d418)


![Figure_1](https://github.com/Naveed776/Safe_expolration_RL_SafetyGym/assets/91262613/1574bb73-3254-4d27-a534-4dd4d401ab6e)


